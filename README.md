<!-- Enhanced README: hero, badges, tech icons, screenshots -->

<p align="center">
	<img src="assets/hero.svg" alt="CrewAI Hero" width="900" />
</p>

# CrewAI â€” Data Analyst Agent

<p align="center">
	<img src="assets/stars.svg" alt="5-star" height="28" />
	&nbsp;&nbsp;
	<img src="assets/badge_crewai.svg" alt="crewai" height="28" />
	<img src="assets/badge_pandas.svg" alt="pandas" height="28" />
	<img src="assets/badge_matplotlib.svg" alt="matplotlib" height="28" />
	<img src="assets/badge_seaborn.svg" alt="seaborn" height="28" />
	<img src="assets/badge_ollama.svg" alt="ollama" height="28" />
</p>

> A professional, modular data-analyst pipeline powered by LLM-driven agents. Feed it a CSV and it will propose cleaning, validate data, suggest visual relationships, generate runnable matplotlib/seaborn code, and produce written insights.

## Quick Links

- Run: `python crew.py`
- Outputs: `outputs/op.py`, `index.html`
- Agents: `agents/` â€” each agent defines its LLM model and endpoint.

## Quick Start

1. Create and activate a virtual environment:

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

2. Start your LLM backend (example: Ollama) and ensure it listens at the address used in `agents/*.py` (default `http://localhost:11434`).

```powershell
ollama serve
```

3. Run the pipeline:

```powershell
python crew.py
```

## What you'll get

- `outputs/op.py` â€” collected Python snippets extracted from agent outputs (if any).
- `index.html` â€” a human-friendly summary (raw JSON + highlighted, copyable code blocks).

## Project Structure

```
â”œâ”€â”€ agents/               # AI agent definitions and configurations
â”‚   â”œâ”€â”€ cleaner.py        # Data cleaning agent
â”‚   â”œâ”€â”€ validator.py      # Data validation agent
â”‚   â”œâ”€â”€ relation.py       # Relationship analysis agent
â”‚   â”œâ”€â”€ code_gen.py       # Code generation agent
â”‚   â””â”€â”€ insights.py       # Insights extraction agent
â”œâ”€â”€ config/               # Configuration files
â”‚   â”œâ”€â”€ llm_config.py     # LLM backend configuration
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ data/                 # Input data directory
â”‚   â””â”€â”€ input.csv         # Default input dataset
â”œâ”€â”€ outputs/              # Generated outputs
â”‚   â””â”€â”€ op.py             # Generated Python code
â”œâ”€â”€ tools/                # Utility functions
â”‚   â”œâ”€â”€ dataframe_ops.py  # DataFrame operations
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ workflows/            # Workflow definitions
â”‚   â”œâ”€â”€ pipeline.py       # Main analysis pipeline
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ assets/               # Static assets for documentation
â”œâ”€â”€ crew.py               # Main entry point
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ USAGE.md              # Detailed usage guide
â”œâ”€â”€ CHANGELOG.md          # Version history
â””â”€â”€ LICENSE               # License information
```

## Customization

### Agent Configuration
Modify agent behaviors by editing files in `agents/`:
- Change LLM models in `config/llm_config.py`
- Update agent prompts and backstories
- Adjust agent roles and goals

### Pipeline Extension
Extend analysis capabilities:
- Add new agents for specific tasks
- Modify `workflows/pipeline.py` for custom workflows
- Integrate additional data sources

### Tool Integration
Add custom utilities in `tools/`:
- Data preprocessing functions
- Custom visualization generators
- Export utilities for different formats

## Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup
1. Fork the repository
2. Create a feature branch: `git checkout -b feature/your-feature`
3. Make your changes and add tests
4. Submit a pull request

### Guidelines
- Follow PEP 8 style guidelines
- Add tests for new features
- Update documentation as needed
- Ensure compatibility with Python 3.8+

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## Support

- ğŸ“– [Usage Guide](USAGE.md)
- ğŸ“‹ [Changelog](CHANGELOG.md)
- ğŸ› [Issues](https://github.com/yourusername/CrewAI-Data-Analyst-Agent/issues)
- ğŸ’¬ [Discussions](https://github.com/yourusername/CrewAI-Data-Analyst-Agent/discussions)

---

*Built with â¤ï¸ using CrewAI and modern Python practices*

